# -*- coding: utf-8 -*-
import sqlite3
import pandas as pd
import numpy as np

def process_market_data(db_path):
    conn = sqlite3.connect(db_path)
    # 1. è®€å–æ•¸æ“š
    query = "SELECT * FROM stock_prices"
    df = pd.read_sql(query, conn)
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['symbol', 'date'])

    processed_list = []
    
    # 2. åˆ†çµ„è¨ˆç®—æŒ‡æ¨™
    for symbol, group in df.groupby('symbol'):
        group = group.copy().sort_values('date')
        
        # --- ğŸŸ¢ è³‡æ–™æ¸…æ´— (Data Cleaning) ---
        # A. è¨ˆç®—å–®æ—¥æ¼²è·Œå¹…ï¼Œç”¨ä¾†åµæ¸¬ç•°å¸¸å€¼ (ä¾‹å¦‚ 8476 ç•°å¸¸çš„ 300% æ¼²å¹…)
        group['daily_change'] = group['close'].pct_change()
        
        # B. å‰”é™¤ç•°å¸¸æ•¸æ“šï¼šå¦‚æœå–®æ—¥æ¼²å¹…æˆ–è·Œå¹…è¶…é 50% ä¸”æˆäº¤é‡ç•°å¸¸ï¼Œ
        # åœ¨é€™è£¡æˆ‘å€‘å¯ä»¥é¸æ“‡ä¿®æ­£å®ƒæˆ–æ¨™è¨˜å®ƒã€‚ç‚ºäº†ç©©å®šæ€§ï¼Œæˆ‘å€‘å°‡æ¥µç«¯ç•°å¸¸å€¼å¹³æ»‘åŒ–
        # (é€™è£¡ä»¥è¶…é 60% ç‚ºä¾‹ï¼Œé¿å…èª¤åˆªé™¤æ¬Šæ¯å¾Œçš„çœŸå¯¦æ³¢å‹•)
        group.loc[abs(group['daily_change']) > 0.6, 'close'] = np.nan
        group['close'] = group['close'].ffill() # ç”¨å‰ä¸€å¤©åƒ¹æ ¼å¡«å……ç•°å¸¸å€¼
        
        if len(group) < 60: continue 

        # --- A. æŒ‡æ¨™è¨ˆç®— (MA, MACD, KD) ---
        group['ma20'] = group['close'].rolling(window=20).mean()
        group['ma60'] = group['close'].rolling(window=60).mean()
        group['ma20_slope'] = (group['ma20'].diff(3) / 3).round(4) # è£œä¸Š round
        group['ma60_slope'] = (group['ma60'].diff(3) / 3).round(4)
        
        # --- å¢åŠ ç‰¹å¾µæ–œç‡è¨ˆç®— ---
        group['ma60_slope'] = (group['ma60'].diff(3) / 3).round(4)
        ema12 = group['close'].ewm(span=12, adjust=False).mean()
        ema26 = group['close'].ewm(span=26, adjust=False).mean()
        group['macd'] = (ema12 - ema26)
        group['macds'] = group['macd'].ewm(span=9, adjust=False).mean()
        group['macdh'] = (group['macd'] - group['macds'])
        group['macdh_slope'] = (group['macdh'].diff(1)).round(4) # æŸ±ç‹€é«”è®ŠåŒ–é€Ÿåº¦
        low_min = group['low'].rolling(window=9).min()
        high_max = group['high'].rolling(window=9).max()
        # é¿å…åˆ†æ¯ç‚º 0
        denominator = high_max - low_min + 1e-9
        rsv = 100 * (group['close'] - low_min) / denominator
        group['k'] = rsv.ewm(com=2, adjust=False).mean()
        group['d'] = group['k'].ewm(com=2, adjust=False).mean()
        group['kd_gold'] = ((group['k'] > group['d']) & (group['k'].shift(1) <= group['d'].shift(1))).astype(int)

        # --- B. åº•éƒ¨èƒŒé›¢ ---
        lookback = 10
        price_low_new = group['close'] < group['close'].shift(1).rolling(window=lookback).min()
        group['macd_bottom_div'] = ((price_low_new) & (group['macdh'] > group['macdh'].shift(1).rolling(window=lookback).min())).astype(int)
        group['kd_bottom_div'] = ((price_low_new) & (group['k'] > group['k'].shift(1).rolling(window=lookback).min())).astype(int)

        # --- ğŸ”µ å¹´åº¦å ±é…¬å°å¸³ (Annual Performance Logic) ---
        # è¨ˆç®—è©²æ—¥æœŸç›¸å°æ–¼è©²å¹´ã€Œç¬¬ä¸€ç­†äº¤æ˜“æ—¥ã€çš„æ¼²è·Œå¹… (å¯¦æ¸¬æ¼²å¹…)
        group['year'] = group['date'].dt.year
        group['year_start_price'] = group.groupby('year')['close'].transform('first')
        group['ytd_ret'] = ((group['close'] - group['year_start_price']) / group['year_start_price'] * 100).round(2)

        # --- C. æœªä¾†å ±é…¬ (æœ€å¤§æ¼²è·Œå¹… % ) ---
        windows = {'1-5': (1, 5), '6-10': (6, 10), '11-20': (11, 20)}
        for label, (s, e) in windows.items():
            f_high = group['high'].shift(-s).rolling(window=(e-s+1)).max()
            group[f'up_{label}'] = ((f_high / group['close'] - 1) * 100).round(2)
            
            f_low = group['low'].shift(-s).rolling(window=(e-s+1)).min()
            group[f'down_{label}'] = ((f_low / group['close'] - 1) * 100).round(2)

        processed_list.append(group)

    # 3. å¯«å›è³‡æ–™åº«
    df_final = pd.concat(processed_list)
    
    # æ¸…é™¤ä¸­é–“è¨ˆç®—ç”¨çš„æ¬„ä½ä»¥ä¿æŒæ•´æ½”
    cols_to_drop = ['daily_change', 'year_start_price']
    df_final = df_final.drop(columns=[c for c in cols_to_drop if c in df_final.columns])
    
    df_final.to_sql('stock_analysis', conn, if_exists='replace', index=False)
    conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis ON stock_analysis (symbol, date)")
    conn.close()
    print(f"âœ… {db_path} ç‰¹å¾µå·¥ç¨‹å®Œæˆ (å«è³‡æ–™æ¸…æ´—èˆ‡ YTD å¯¦æ¸¬æ¼²å¹…)")
