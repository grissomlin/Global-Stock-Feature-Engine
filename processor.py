# -*- coding: utf-8 -*-
import sqlite3
import pandas as pd
import pandas_ta as ta
import numpy as np
from datetime import datetime

def process_market_data(db_path):
    """
    é‡åŒ–ç‰¹å¾µå·¥ç¨‹æ ¸å¿ƒï¼šåŒ…å«ç•°å¸¸æ¸…æ´—ã€å¸‚å ´æ„ŸçŸ¥ã€æŒ‡æ¨™è¨ˆç®—èˆ‡æœªä¾†å ±é…¬æ¨™ç±¤
    """
    conn = sqlite3.connect(db_path)
    
    # 1. è®€å–åƒ¹æ ¼æ•¸æ“šä¸¦é—œè¯å¸‚å ´åˆ†é¡ (ç¢ºä¿å¾ stock_info å–å¾— market æ¬„ä½)
    query = """
        SELECT p.*, i.market, i.name
        FROM stock_prices p
        LEFT JOIN stock_info i ON p.symbol = i.symbol
    """
    df = pd.read_sql(query, conn)
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['symbol', 'date'])

    # --- 2. æ•¸æ“šæ¸…æ´—ï¼šå¸‚å ´æ„ŸçŸ¥æ¼²è·Œå¹…éæ¿¾ ---
    print(f"ğŸ“¡ æ­£åœ¨å° {db_path} åŸ·è¡Œå¸‚å ´æ„ŸçŸ¥æ•¸æ“šæ¸…æ´—...")
    df['daily_return'] = df.groupby('symbol')['close'].pct_change()

    def check_anomaly(row):
        # å¦‚æœæ˜¯ç©ºå€¼å‰‡è·³é
        if pd.isna(row['daily_return']): return False
        ret = abs(row['daily_return'])
        
        # ä¸Šå¸‚æ«ƒ (listed/otc/dr) åš´æ ¼åŸ·è¡Œ 11% éæ¿¾ (è€ƒé‡é™¤æ¯å¾®èª¿)
        if row['market'] in ['listed', 'otc', 'dr', 'tw_innovation']:
            return ret > 0.11
        # ETF æ§“æ¡¿æ³¢å‹•è¼ƒå¤§ï¼Œè¨­ç‚º 20%
        if row['market'] == 'etf':
            return ret > 0.20
        # èˆˆæ«ƒ (rotc) ç„¡é™åˆ¶ï¼Œä½†è¶…é 100% ä»è¦–ç‚ºç•°å¸¸æˆ–éœ€æ ¸å¯¦æ•¸æ“š
        if row['market'] == 'rotc':
            return ret > 1.00
        return False

    df['is_anomaly'] = df.apply(check_anomaly, axis=1)
    bad_symbols = df[df['is_anomaly'] == True]['symbol'].unique()
    
    if len(bad_symbols) > 0:
        print(f"ğŸ›‘ å‰”é™¤ç•°å¸¸è®Šå‹•æ¨™çš„ (å…± {len(bad_symbols)} æª”): {list(bad_symbols)}")
        df = df[~df['symbol'].isin(bad_symbols)]

    # --- 3. æ•¸æ“šé©—è­‰ï¼šå¹´åº¦åƒ¹æ ¼å°å¸³ ---
    print("ğŸ•µï¸ åŸ·è¡Œå¹´åº¦åƒ¹æ ¼å°å¸³ (å¹´åº¦å ±é…¬åˆç†æ€§æª¢æŸ¥)...")
    df['year'] = df['date'].dt.year
    for yr in df['year'].unique():
        year_subset = df[df['year'] == yr]
        if year_subset.empty: continue
        
        # æª¢æŸ¥è©²å¹´åº¦æ¼²å¹…æ˜¯å¦è¶…é 500% (é˜²ç¯„å¦‚è½‰æ¿ã€æ¸›è³‡æœªé‚„åŸä¹‹éŒ¯èª¤)
        yr_check = year_subset.groupby('symbol').agg(
            first_p=('close', 'first'),
            last_p=('close', 'last')
        )
        yr_check['yr_ret'] = (yr_check['last_p'] - yr_check['first_p']) / yr_check['first_p']
        crazy_stocks = yr_check[yr_check['yr_ret'] > 5.0].index.tolist()
        if crazy_stocks:
            print(f"âš ï¸ {yr} å¹´åµæ¸¬åˆ°è¶…å¸¸å¹´æ¼²å¹… (>500%): {crazy_stocks}ï¼Œå·²å¾åˆ†æä¸­ç§»é™¤ã€‚")
            df = df[~df['symbol'].isin(crazy_stocks)]

    # --- 4. ç‰¹å¾µå·¥ç¨‹ï¼šæŠ€è¡“æŒ‡æ¨™èˆ‡èƒŒé›¢è¨ˆç®— ---
    print("ğŸ§ª è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (MA, KD, MACD) èˆ‡èƒŒé›¢è¨Šè™Ÿ...")
    processed_list = []
    
    for symbol, group in df.groupby('symbol'):
        group = group.copy().sort_values('date')
        
        # å‡ç·šé«”ç³»
        group['ma5'] = ta.sma(group['close'], length=5)
        group['ma20'] = ta.sma(group['close'], length=20)
        group['ma60'] = ta.sma(group['close'], length=60)
        
        # KD æŒ‡æ¨™ (9, 3, 3)
        kd = ta.stoch(group['high'], group['low'], group['close'], k=9, d=3)
        group['k'], group['d'] = kd['STOCHk_9_3_3'], kd['STOCHd_9_3_3']
        
        # MACD æŒ‡æ¨™
        macd = ta.macd(group['close'])
        group['macd'], group['macds'] = macd['MACD_12_26_9'], macd['MACDS_12_26_9']
        
        # é»ƒé‡‘äº¤å‰åˆ¤å®š
        group['kd_gold'] = (group['k'] > group['d']) & (group['k'].shift(1) <= group['d'].shift(1))
        group['macd_gold'] = (group['macd'] > group['macds']) & (group['macd'].shift(1) <= group['macds'].shift(1))
        
        # ä½æª”èƒŒé›¢ (åƒ¹æ ¼å‰µä½ä½†æŒ‡æ¨™æœªå‰µä½ - ç°¡åŒ–é‚è¼¯)
        group['low_divergence'] = (group['close'] < group['close'].shift(3)) & (group['macd'] > group['macd'].shift(3))

        # --- 5. æ¨™ç±¤å·¥ç¨‹ï¼šæœªä¾†å€é–“æœ€å¤§æ¼²è·Œå¹… (Demo æ ¸å¿ƒ) ---
        windows = {'1-5': (1, 5), '6-10': (6, 10), '11-20': (11, 20), '21-30': (21, 30)}
        for label, (s, e) in windows.items():
            # å–å¾—æœªä¾†è¦–çª—å…§çš„æ¥µå€¼
            # ä¾‹å¦‚ 1-5 ä»£è¡¨ä»Šå¤©ä¹‹å¾Œçš„ç¬¬ 1 åˆ°ç¬¬ 5 å¤©
            f_high = group['high'].shift(-s).rolling(window=(e-s+1)).max()
            f_low = group['low'].shift(-s).rolling(window=(e-s+1)).min()
            
            group[f'up_{label}'] = (f_high / group['close'] - 1).round(4)
            group[f'down_{label}'] = (f_low / group['close'] - 1).round(4)

        processed_list.append(group)

    # --- 6. å¯«å›è³‡æ–™åº« ---
    df_final = pd.concat(processed_list)
    # åˆªé™¤è¼”åŠ©ç”¨çš„æ¬„ä½ä»¥ç¯€çœç©ºé–“
    df_final = df_final.drop(columns=['is_anomaly', 'daily_return', 'year'])
    
    print(f"ğŸ’¾ æ­£åœ¨å°‡åŠ å·¥å¾Œçš„æ•¸æ“šå¯«å…¥ stock_analysis è¡¨...")
    df_final.to_sql('stock_analysis', conn, if_exists='replace', index=False)
    
    # å¼·åˆ¶å»ºç«‹ç´¢å¼•ï¼šé€™å° Streamlit æŸ¥è©¢æ¥µå…¶é‡è¦
    conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis_sym_date ON stock_analysis (symbol, date)")
    conn.close()
    print(f"âœ¨ {db_path} è™•ç†å®Œæˆï¼")

if __name__ == "__main__":
    # æ¸¬è©¦ç”¨
    process_market_data("tw_stock_warehouse.db")
