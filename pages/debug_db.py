import streamlit as st
import sqlite3
import pandas as pd
import os

st.set_page_config(page_title="DB é™¤éŒ¯å·¥å…·", layout="wide")

st.title("ğŸ” SQLite è³‡æ–™åº«åº•å±¤è¨ºæ–·å·¥å…·")

# å®šç¾©è¦æª¢æŸ¥çš„è³‡æ–™åº«åç¨±
DB_NAME = "tw_stock_warehouse.db"

if not os.path.exists(DB_NAME):
    st.error(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {DB_NAME}")
    st.info("è«‹ç¢ºèª GitHub Actions æ˜¯å¦å·²æˆåŠŸå°‡æª”æ¡ˆåŒæ­¥è‡³é›²ç«¯ï¼Œä¸”ä¸‹è¼‰é‚è¼¯æ­£å¸¸åŸ·è¡Œã€‚")
else:
    st.success(f"âœ… åµæ¸¬åˆ°è³‡æ–™åº«æª”æ¡ˆ: {DB_NAME}")
    
    # å»ºç«‹é€£ç·š
    conn = sqlite3.connect(DB_NAME)
    
    # --- 1. æª¢æŸ¥æ‰€æœ‰è¡¨æ ¼ ---
    st.header("1. è³‡æ–™è¡¨æ¸…å–® (Tables)")
    tables = pd.read_sql("SELECT name FROM sqlite_master WHERE type='table'", conn)
    st.table(tables)
    
    if not tables.empty:
        # è®“ä½¿ç”¨è€…é¸æ“‡è¦æª¢æŸ¥çš„è¡¨æ ¼ (é è¨­ç‚º stock_analysis)
        target_table = st.selectbox("é¸æ“‡è¦è¨ºæ–·çš„è¡¨æ ¼", tables['name'].tolist(), 
                                     index=tables['name'].tolist().index('stock_analysis') if 'stock_analysis' in tables['name'].tolist() else 0)
        
        st.divider()
        
        # --- 2. æª¢æŸ¥æ¬„ä½çµæ§‹ (Schema) ---
        st.header(f"2. `{target_table}` æ¬„ä½çµæ§‹ (Schema)")
        # PRAGMA table_info æ˜¯ SQLite æŸ¥çœ‹æ¬„ä½å®šç¾©æœ€ç›´æ¥çš„æ–¹å¼
        schema_df = pd.read_sql(f"PRAGMA table_info({target_table})", conn)
        
        # æ¨™è‰²é¡¯ç¤ºï¼šå¦‚æœæ¬„ä½åŒ…å« slopeï¼Œç‰¹åˆ¥æ¨™è¨»
        def highlight_slope(s):
            return ['background-color: #ffffb3' if 'slope' in str(val) else '' for val in s]
        
        st.dataframe(schema_df.style.apply(highlight_slope, axis=1), use_container_width=True)
        
        # --- 3. æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥ ---
        st.header(f"3. `{target_table}` æ•¸æ“šå®Œæ•´æ€§çµ±è¨ˆ")
        col1, col2, col3 = st.columns(3)
        
        try:
            total_rows = pd.read_sql(f"SELECT COUNT(*) as count FROM {target_table}", conn).iloc[0]['count']
            col1.metric("ç¸½åˆ—æ•¸ (Rows)", f"{total_rows:,}")
            
            date_range = pd.read_sql(f"SELECT MIN(date) as start, MAX(date) as end FROM {target_table}", conn)
            col2.metric("è³‡æ–™èµ·é»", str(date_range.iloc[0]['start']))
            col3.metric("è³‡æ–™çµ‚é» (æœ€æ–°æ—¥æœŸ)", str(date_range.iloc[0]['end']))
        except:
            st.warning("ç„¡æ³•è®€å–æ•¸æ“šçµ±è¨ˆï¼Œè«‹ç¢ºèªæ¬„ä½åç¨±æ˜¯å¦åŒ…å« 'date'")

        st.divider()

        # --- 4. åŸå§‹æ•¸æ“šé è¦½ ---
        st.header(f"4. `{target_table}` åŸå§‹æ•¸æ“šé è¦½ (æœ€å¾Œ 50 ç­†)")
        # æŠ“å–æœ€å¾Œ 50 ç­†ï¼Œæ–¹ä¾¿çœ‹æœ€æ–°çš„è³‡æ–™æœ‰æ²’æœ‰æ–œç‡
        try:
            preview_df = pd.read_sql(f"SELECT * FROM {target_table} ORDER BY date DESC, symbol ASC LIMIT 50", conn)
            st.dataframe(preview_df, use_container_width=True)
        except Exception as e:
            st.error(f"è®€å–é è¦½å¤±æ•—: {e}")

    conn.close()

st.sidebar.info("""
**é™¤éŒ¯ SOP:**
1. å¦‚æœ **2. æ¬„ä½çµæ§‹** æ²’çœ‹åˆ° `ma60_slope`ï¼Œä»£è¡¨ `processor.py` æ²’è·‘æˆåŠŸã€‚
2. å¦‚æœ **3. è³‡æ–™çµ‚é»** å¤ªèˆŠï¼Œä»£è¡¨ `main.py` çš„ä¸‹è¼‰å™¨æ²’æ›´æ–°ã€‚
3. å¦‚æœ **4. æ•¸æ“šé è¦½** è£¡æ–œç‡å…¨æ˜¯ `NaN`ï¼Œä»£è¡¨è©²è‚¡ç¥¨è³‡æ–™é•·åº¦ä¸è¶³è¨ˆç®—æŒ‡æ¨™ã€‚
""")
