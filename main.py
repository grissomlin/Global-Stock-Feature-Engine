# -*- coding: utf-8 -*-
import os, sys, sqlite3, json, time, socket, io
import pandas as pd
from datetime import datetime
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from dotenv import load_dotenv

# ğŸ’¡ è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv() 
socket.setdefaulttimeout(600)

# ğŸ’¡ ç’°å¢ƒè®Šæ•¸è®€å–
GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID')
SERVICE_ACCOUNT_FILE = 'citric-biplane-319514-75fead53b0f5.json'

# ğŸ’¡ å°å…¥æ¨¡çµ„
try:
    from processor import process_market_data
except ImportError:
    print("âš ï¸ ç³»çµ±æç¤ºï¼šæ‰¾ä¸åˆ° processor.pyï¼Œå°‡è·³éç‰¹å¾µå·¥ç¨‹ã€‚")
    process_market_data = None

try:
    from notifier import StockNotifier
    notifier = StockNotifier()
except Exception as e:
    print(f"âš ï¸ ç³»çµ±æç¤ºï¼šNotifier åˆå§‹åŒ–è·³é (åŸå› : {e})")
    notifier = None

import downloader_tw, downloader_us, downloader_cn, downloader_hk, downloader_jp, downloader_kr

# ğŸ“Š é æœŸæ•¸é‡ç›£æ§
EXPECTED_MIN_STOCKS = {
    'tw': 2500, 'us': 5684, 'cn': 5496, 'hk': 2689, 'jp': 4315, 'kr': 2000
}

# ========== Google Drive æœå‹™å‡½å¼ ==========

def get_drive_service():
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(
                info, scopes=['https://www.googleapis.com/auth/drive']
            )
        elif os.path.exists(SERVICE_ACCOUNT_FILE):
            creds = service_account.Credentials.from_service_account_file(
                SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/drive']
            )
        else:
            return None
        return build('drive', 'v3', credentials=creds, cache_discovery=False)
    except Exception as e:
        print(f"âŒ Drive æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
        return None

def download_db_from_drive(service, file_name):
    if not GDRIVE_FOLDER_ID: return False
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    try:
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        if not items: return False
        file_id = items[0]['id']
        print(f"ğŸ“¡ å¾é›²ç«¯ä¸‹è¼‰è³‡æ–™åº«: {file_name}")
        request = service.files().get_media(fileId=file_id)
        with io.FileIO(file_name, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request, chunksize=5*1024*1024)
            done = False
            while not done: _, done = downloader.next_chunk()
        return True
    except: return False

def upload_to_drive(service, file_path, mimetype='application/x-sqlite3'):
    """é€šç”¨ä¸Šå‚³å‡½å¼ï¼Œæ”¯æ´æ›´æ–°èˆ‡æ–°å»º"""
    if not GDRIVE_FOLDER_ID or not os.path.exists(file_path): return False
    file_name = os.path.basename(file_path)
    media = MediaFileUpload(file_path, mimetype=mimetype, resumable=True)
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    try:
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        if items:
            service.files().update(fileId=items[0]['id'], media_body=media).execute()
        else:
            meta = {'name': file_name, 'parents': [GDRIVE_FOLDER_ID]}
            service.files().create(body=meta, media_body=media).execute()
        print(f"âœ… ä¸Šå‚³æˆåŠŸ: {file_name}")
        return True
    except Exception as e:
        print(f"âš ï¸ {file_name} ä¸Šå‚³å¤±æ•—: {e}")
        return False

def get_db_summary(db_path, market_id):
    if not os.path.exists(db_path): return None
    try:
        conn = sqlite3.connect(db_path)
        df_stats = pd.read_sql("SELECT COUNT(DISTINCT symbol) as s, MAX(date) as d2 FROM stock_prices", conn)
        conn.close()
        success_count = int(df_stats['s'][0]) if df_stats['s'][0] else 0
        latest_date = str(df_stats['d2'][0]) if df_stats['d2'][0] else "N/A"
        expected = EXPECTED_MIN_STOCKS.get(market_id, 1)
        coverage = (success_count / expected) * 100
        return {
            "market": market_id.upper(), "expected": expected, "success": success_count,
            "coverage": f"{coverage:.1f}%", "end_date": latest_date,
            "status": "âœ…" if 80 <= coverage <= 120 else "âš ï¸"
        }
    except: return None

# ========== ä¸»ç¨‹å¼é‚è¼¯ ==========

def main():
    target_market = sys.argv[1].lower() if len(sys.argv) > 1 else None
    module_map = {
        'tw': downloader_tw, 'us': downloader_us, 'cn': downloader_cn, 
        'hk': downloader_hk, 'jp': downloader_jp, 'kr': downloader_kr
    }
    
    markets_to_run = [target_market] if target_market in module_map else list(module_map.keys())
    service = get_drive_service()
    all_summaries = []

    for m in markets_to_run:
        db_file = f"{m}_stock_warehouse.db"
        print(f"\n--- ğŸŒ å¸‚å ´å•Ÿå‹•: {m.upper()} ---")

        if service and not os.path.exists(db_file):
            download_db_from_drive(service, db_file)

        target_module = module_map.get(m)
        print(f"ğŸš€ æ­£åœ¨ä¸‹è¼‰/æ›´æ–°åŸå§‹æ•¸æ“š...")
        target_module.run_sync(start_date="2024-01-01", end_date="2025-12-31")
        
        if process_market_data and os.path.exists(db_file):
            print(f"ğŸ§ª æ­£åœ¨åŸ·è¡Œç‰¹å¾µå·¥ç¨‹...")
            process_market_data(db_file)
        
        summary = get_db_summary(db_file, m)
        if summary:
            all_summaries.append(summary)
            print(f"ğŸ“Š æ‘˜è¦: {summary['market']} | æ¶µè“‹ç‡: {summary['coverage']} | æœ€å¾Œæ—¥æœŸ: {summary['end_date']}")
            # ğŸ’¡ æ–°å¢ï¼šç”Ÿæˆè©²å¸‚å ´çš„ç¨ç«‹æ‘˜è¦æ–‡ä»¶
            market_summary_file = f"summary_{m}.json"
            with open(market_summary_file, "w", encoding="utf-8") as f:
                json.dump(summary, f, ensure_ascii=False, indent=4)
            print(f"ğŸ“ å·²ç”Ÿæˆå¸‚å ´æ‘˜è¦æ–‡ä»¶: {market_summary_file}")
        if service and os.path.exists(db_file):
            print(f"ğŸ§¹ å„ªåŒ–ä¸¦åŒæ­¥é›²ç«¯...")
            try:
                conn = sqlite3.connect(db_file)
                conn.execute("VACUUM")
                conn.close()
                upload_to_drive(service, db_file)
            except Exception as e:
                print(f"âŒ é›²ç«¯åŒæ­¥å¤±æ•—: {e}")

    # --- ğŸŒ æ–°å¢ï¼šå…¨çƒç‰¹å¾µæ‘˜è¦ JSON ç”Ÿæˆèˆ‡ä¸Šå‚³ ---
    if all_summaries:
        print("\nğŸŒ æ­£åœ¨ç”Ÿæˆå…¨çƒå¸‚å ´ç‰¹å¾µæ‘˜è¦...")
        if len(markets_to_run) > 1:
            json_file = "global_summary.json"
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(all_summaries, f, ensure_ascii=False, indent=4)
            
            if service:
                print(f"ğŸ“¡ æ­£åœ¨åŒæ­¥ {json_file} è‡³é›²ç«¯...")
                upload_to_drive(service, json_file, mimetype='application/json')

    # 6. ç™¼é€å ±å‘Š
    if notifier and all_summaries:
        print("ğŸ“¨ æ­£åœ¨ç™¼é€ Email å ±å‘Š...")
        try:
            notifier.send_stock_report_email(all_summaries)
        except Exception as e:
            print(f"âŒ å ±å‘Šç™¼é€å¤±æ•—: {e}")

if __name__ == "__main__":
    main()

