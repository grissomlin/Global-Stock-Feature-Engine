import streamlit as st
import sqlite3
import pandas as pd
import os
from datetime import datetime

st.set_page_config(page_title="Global Stock Feature Engine", layout="wide")

def get_all_db_files():
    """å°‹æ‰¾ç›®éŒ„ä¸‹æ‰€æœ‰çš„è³‡æ–™åº«æª”æ¡ˆ"""
    return [f for f in os.listdir('.') if f.endswith('_stock_warehouse.db')]

def get_db_metadata(db_name):
    """å–å¾—è³‡æ–™åº«çš„çµ±è¨ˆè³‡è¨Š"""
    try:
        conn = sqlite3.connect(db_name)
        # æª¢æŸ¥æ˜¯å¦æœ‰åŠ å·¥å¾Œçš„è¡¨æ ¼
        tables = pd.read_sql("SELECT name FROM sqlite_master WHERE type='table'", conn)
        has_analysis = 'stock_analysis' in tables['name'].values
        target_table = 'stock_analysis' if has_analysis else 'stock_prices'
        
        df_stats = pd.read_sql(f"""
            SELECT 
                COUNT(DISTINCT symbol) as total_symbols,
                MIN(date) as start_date,
                MAX(date) as end_date,
                COUNT(*) as total_rows
            FROM {target_table}
        """, conn)
        
        # å–å¾—æ¬„ä½åç¨±ä»¥ä¾›åƒè€ƒ
        columns = pd.read_sql(f"PRAGMA table_info({target_table})", conn)['name'].tolist()
        conn.close()
        
        return {
            "db": db_name,
            "table": target_table,
            "symbols": df_stats['total_symbols'][0],
            "start": df_stats['start_date'][0],
            "end": df_stats['end_date'][0],
            "rows": df_stats['total_rows'][0],
            "columns": columns
        }
    except Exception as e:
        return {"db": db_name, "error": str(e)}

# --- UI ä»‹é¢ ---
st.title("ğŸŒ å…¨çƒè‚¡å¸‚ç‰¹å¾µå¼•æ“ - è³‡æ–™åº«æª¢æŸ¥å„€è¡¨æ¿")

db_files = get_all_db_files()

if not db_files:
    st.warning("âŒ æ‰¾ä¸åˆ°ä»»ä½• *_stock_warehouse.db æª”æ¡ˆï¼Œè«‹ç¢ºèªæª”æ¡ˆå·²ä¸‹è¼‰è‡³æœ¬åœ°ã€‚")
else:
    # 1. ç¸½è¦½å€
    st.header("ğŸ“Š è³‡æ–™åº«å¥åº·åº¦æƒæ")
    meta_data = []
    for db in db_files:
        meta_data.append(get_db_metadata(db))
    
    df_meta = pd.DataFrame(meta_data)
    st.table(df_meta[['db', 'table', 'symbols', 'start', 'end', 'rows']])

    # 2. è©³ç´°æ¬„ä½èˆ‡æ•¸æ“šé è¦½
    st.divider()
    selected_db = st.selectbox("é¸æ“‡è¦æª¢è¦–çš„è³‡æ–™åº«", db_files)
    
    if selected_db:
        curr_meta = next(item for item in meta_data if item["db"] == selected_db)
        
        col1, col2 = st.columns([1, 3])
        
        with col1:
            st.subheader("ğŸ“‹ æ¬„ä½æ¸…å–® (Features)")
            st.write(curr_meta['columns'])
        
        with col2:
            st.subheader("ğŸ” æ•¸æ“šæŠ½æ¨£ (Top 100)")
            conn = sqlite3.connect(selected_db)
            # å„ªå…ˆå±•ç¤ºå…·æœ‰ç‰¹å¾µçš„æ•¸æ“š
            df_preview = pd.read_sql(f"SELECT * FROM {curr_meta['table']} LIMIT 100", conn)
            st.dataframe(df_preview, use_container_width=True)
            
            # ç‰¹å¾µåˆ†ä½ˆå¿«é€Ÿæª¢æŸ¥
            if 'macdh_slope' in df_preview.columns:
                st.subheader("ğŸ“ˆ æŒ‡æ¨™è®Šå‹•æª¢æŸ¥ (ç¤ºä¾‹ï¼šMACD æ–œç‡)")
                st.line_chart(df_preview.set_index('date')['macdh_slope'].head(50))
            
            conn.close()

    # 3. ç•°å¸¸æª¢ç´¢ (é¸é…)
    with st.expander("ğŸ› ï¸ é€²éšæª¢æŸ¥ï¼šæœå°‹ç‰¹å®šæ¨™çš„"):
        search_symbol = st.text_input("è¼¸å…¥æ¨™çš„ä»£è™Ÿ (ä¾‹å¦‚: 2330.TW)", "")
        if search_symbol and selected_db:
            conn = sqlite3.connect(selected_db)
            res = pd.read_sql(f"SELECT * FROM {curr_meta['table']} WHERE symbol = '{search_symbol}' ORDER BY date DESC LIMIT 20", conn)
            st.write(res)
            conn.close()
